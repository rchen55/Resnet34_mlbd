{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d51427-add0-4b25-967e-add57d822594",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5c8d2e-2955-43e9-9799-211f55a7b0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88bdb32-6690-4b8e-b67d-94ddd262bf28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8a7fbc-fbcc-45dc-bb61-1f1ca3ab1480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, phase='Train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "\n",
    "        sub_dirs = ['Brown_Field', 'Main_Trail', 'Power_Line', 'mixed']\n",
    "\n",
    "        for sub_dir in sub_dirs:\n",
    "            subdir_path = os.path.join(root_dir, sub_dir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                img_dir = os.path.join(subdir_path, phase, 'imgs')\n",
    "                mask_dir = os.path.join(subdir_path, phase, 'annos', 'int_maps')\n",
    "\n",
    "                if os.path.exists(img_dir) and os.path.exists(mask_dir):\n",
    "                    img_files = sorted([f for f in os.listdir(img_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "                    mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "                    if len(img_files) == 0 or len(mask_files) == 0:\n",
    "                        print(f\"No images or masks found in {img_dir} or {mask_dir}\")\n",
    "                    else:\n",
    "                        for img_file, mask_file in zip(img_files, mask_files):\n",
    "                            self.image_paths.append(os.path.join(img_dir, img_file))\n",
    "                            self.mask_paths.append(os.path.join(mask_dir, mask_file))\n",
    "                else:\n",
    "                    print(f\"Image directory {img_dir} or mask directory {mask_dir} does not exist\")\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            print(\"No images or masks found in any subdirectory\")\n",
    "        else:\n",
    "            print(f\"Found {len(self.image_paths)} images and {len(self.mask_paths)} masks\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert('L').resize((224,224), resample=Image.NEAREST)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        # Convert mask to binary (0 and 1)\n",
    "        mask = (mask > 0).float()\n",
    "        \n",
    "        transforms.Resize((224, 224)),\n",
    "        mask = np.array(mask)\n",
    "        mask = torch.tensor(mask, dtype=torch.int64)\n",
    "        \n",
    "        # squeeze the tensor\n",
    "        mask = torch.squeeze(mask)\n",
    "        # print the squeezed tensor\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy calculation function\n",
    "def calculate_accuracy(outputs, masks):\n",
    "    preds = torch.sigmoid(outputs) > 0.5  # Threshold predictions at 0.5\n",
    "    correct = (preds == masks).float()\n",
    "    accuracy = correct.sum() / correct.numel()\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a1d6c-f59b-4c7b-9209-bb2e85263d43",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76011-7a4f-44c4-b057-dda6d96b6b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Compose([\n",
    "    \n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bacb66-337e-4796-8088-1dc41b3558bf",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ec76dd-e4aa-49e1-86b3-19fa01348764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2536 images and 2536 masks\n",
      "Found 1088 images and 1088 masks\n",
      "Found 2536 images and 2536 masks\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/rchen2/CAT'\n",
    "\n",
    "train_dataset = CustomDataset(root_dir=root_dir, phase='Train', transform=data_transforms)\n",
    "test_dataset = CustomDataset(root_dir=root_dir, phase='Test', transform=data_transforms)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, phase='Train', transform=val_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Accuracy calculation function\n",
    "def calculate_accuracy(predictions, ground_truth):\n",
    "    # Assuming predictions and ground_truth are binary masks with values 0 or 1\n",
    "    correct = np.sum(predictions == ground_truth)\n",
    "    total = predictions.size\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea24e19e-8615-43b5-bd4e-58a8df72ba1c",
   "metadata": {},
   "source": [
    "### Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05dd176-2f7e-4b0d-bb33-a79c4e4ac53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = smp.Unet(encoder_name = \"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=4,).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ec1d4-1cb1-4cf0-b876-2997d3eec193",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d762501-0ca3-4aec-ae5e-1357cb60951b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rchen2/.conda/envs/mlbd/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "Training Epoch 1:   0%|          | 0/80 [00:00<?, ?it/s]/home/rchen2/.conda/envs/mlbd/lib/python3.7/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Training Epoch 1: 100%|██████████| 80/80 [19:26<00:00, 14.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 0.6237573485821486\n",
      "Epoch [1] IoU per class: [0.38296619405795673, 0.6628771161735837, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 80/80 [06:28<00:00,  4.85s/it]\n",
      "/home/rchen2/.conda/envs/mlbd/lib/python3.7/site-packages/ipykernel_launcher.py:100: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5287993714213371\n",
      "Mean IoU: 0.5537591658528216\n",
      "IoU per class: [0.4088495663423434, 0.6986687653632997, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 80/80 [18:45<00:00, 14.06s/it]\n",
      "/home/rchen2/.conda/envs/mlbd/lib/python3.7/site-packages/ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2] Training Loss: 0.36221774891018865\n",
      "Epoch [2] IoU per class: [0.40503623090097635, 0.7376561658433549, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 80/80 [06:27<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4738102236762643\n",
      "Mean IoU: 0.5956204516944662\n",
      "IoU per class: [0.48307979323398753, 0.7081611101549449, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 80/80 [18:45<00:00, 14.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3] Training Loss: 0.33280202820897103\n",
      "Epoch [3] IoU per class: [0.4285358151115994, 0.7481885097980725, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 80/80 [06:28<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3783735426142812\n",
      "Mean IoU: 0.5865965558673774\n",
      "IoU per class: [0.44439337578582094, 0.7287997359489337, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  90%|█████████ | 72/80 [17:04<01:53, 14.16s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, num_epochs, device, num_classes):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.train_iou_per_class = []\n",
    "        self.scaler = GradScaler()  # For mixed precision training\n",
    "\n",
    "    def calculate_iou(self, pred, target):\n",
    "        iou_per_class = []\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            pred_inds = (pred == cls)\n",
    "            target_inds = (target == cls)\n",
    "\n",
    "            intersection = (pred_inds & target_inds).sum().item()\n",
    "            union = (pred_inds | target_inds).sum().item()\n",
    "\n",
    "            if union == 0:\n",
    "                iou_per_class.append(float('nan'))\n",
    "            else:\n",
    "                iou_per_class.append(intersection / union)\n",
    "\n",
    "        return iou_per_class\n",
    "\n",
    "    def mean_iou(self, iou_list):\n",
    "        valid_iou = [iou for iou in iou_list if not np.isnan(iou)]\n",
    "        if len(valid_iou) == 0:\n",
    "            return float('nan')\n",
    "        return np.mean(valid_iou)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        iou_scores = []\n",
    "\n",
    "        for images, masks in tqdm(self.train_loader, desc=f'Training Epoch {epoch}'):\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            with autocast():  # Mixed precision context\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, masks)\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate IoU\n",
    "            iou = self.calculate_iou(outputs, masks)\n",
    "            iou_scores.append(iou)\n",
    "\n",
    "        avg_loss = running_loss / len(self.train_loader)\n",
    "        avg_iou_scores = np.nanmean(iou_scores, axis=0)\n",
    "        self.train_iou_per_class.append(avg_iou_scores)\n",
    "\n",
    "        print(f\"Epoch [{epoch}] Training Loss: {avg_loss}\")\n",
    "        print(f\"Epoch [{epoch}] IoU per class: {avg_iou_scores.tolist()}\")  # Convert to list for safe printing\n",
    "        return avg_loss\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        iou_scores = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(self.val_loader, desc='Validating'):\n",
    "                images = images.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, masks)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Calculate IoU\n",
    "                iou = self.calculate_iou(outputs, masks)\n",
    "                iou_scores.append(iou)\n",
    "\n",
    "            avg_loss = running_loss / len(self.val_loader)\n",
    "\n",
    "            # Compute mean IoU\n",
    "            iou_scores = np.array(iou_scores)\n",
    "            miou_per_class = np.nanmean(iou_scores, axis=0)\n",
    "            miou = self.mean_iou(miou_per_class)\n",
    "\n",
    "            print(f\"Validation Loss: {avg_loss}\")\n",
    "            print(f\"Mean IoU: {miou}\")\n",
    "            print(f\"IoU per class: {miou_per_class.tolist()}\")  # Convert to list for safe printing\n",
    "            return avg_loss, miou, miou_per_class\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            val_loss, val_miou, val_miou_per_class = self.validate_epoch()\n",
    "\n",
    "# Example usage:\n",
    "# Define the number of epochs\n",
    "num_epochs = 4\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Define class weights based on the dataset\n",
    "class_weights = torch.tensor([1.0, 2.0, 2.0, 2.0]).to(device)\n",
    "\n",
    "# Use weighted loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Create a trainer instance\n",
    "trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, num_classes)\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebd339-54eb-4799-b633-7bb9ac6bcb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_iou_per_class(trainer, num_epochs):\n",
    "    epochs = np.arrange(1, num_epochs+1)\n",
    "    iou_per_class == np.array(trainer.train_iou_per_class).T\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    classNames = ['Background', 'Sedan', 'Pickup', 'Off-Road']\n",
    "    for cls in range(num_classes):\n",
    "        plt.plot(epochs, iou_per_class[cls], label=f'{classNames[cls]} IoU')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.title('ResNet-34')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_iou_per_class(trainer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
